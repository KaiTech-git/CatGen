{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training Description\n",
        "DCGAN model training based on the [article](https://arxiv.org/abs/1511.06434) and torch [implementation](https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html). Model were trained based on over 1000 photos of British Shorthair orange cat. In the process of augmentation training data were extended to over 80,000 photos. Training lasted 5 epochs and was performed on photos with background."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chUZ1Dp9v5h0",
        "outputId": "8caf135e-2fc8-44e5-9c1a-1e3b08a5ec91"
      },
      "outputs": [],
      "source": [
        "\n",
        "%pip install torch\n",
        "%pip install torchvision\n",
        "%pip install numpy\n",
        "%pip install matplotlib\n",
        "%pip install IPython\n",
        "%pip install pickle\n",
        "%pip install opencv-python\n",
        "%pip install plotly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i67C__5YxTKE"
      },
      "outputs": [],
      "source": [
        "import pathlib\n",
        "from PIL import Image\n",
        "from google.colab import drive\n",
        "import plotly.express as px\n",
        "import cv2\n",
        "import pickle\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.parallel\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.utils as vutils\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from IPython.display import HTML\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gGWPGeLAmlJa",
        "outputId": "0bf68ca6-c65d-4965-a6a2-7b33cbe95ff8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Random Seed:  999\n"
          ]
        }
      ],
      "source": [
        "# Set random seed for reproducibility\n",
        "manualSeed = 999\n",
        "# manualSeed = random.randint(1, 10000)  use if you want new results\n",
        "print(\"Random Seed: \", manualSeed)\n",
        "random.seed(manualSeed)\n",
        "torch.manual_seed(manualSeed)\n",
        "torch.use_deterministic_algorithms(True) # Needed for reproducible results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tOCbM79oWgc"
      },
      "source": [
        "# Model Input"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AL77eniYnSWM"
      },
      "outputs": [],
      "source": [
        "# Root directory for dataset\n",
        "dataroot = \"/content/drive/MyDrive/Colab Notebooks/CatGen/data/3.Photos_64px\"\n",
        "\n",
        "# Number of workers for dataloader\n",
        "workers = 8\n",
        "\n",
        "# Batch size during training\n",
        "batch_size = 64\n",
        "\n",
        "# Spatial size of training images. All images will be resized to this\n",
        "#   size using a transformer.\n",
        "image_size = 64\n",
        "\n",
        "# Number of channels in the training images. For color images this is 3\n",
        "nc = 3\n",
        "\n",
        "# Size of z latent vector (i.e. size of generator input)\n",
        "nz = 100\n",
        "\n",
        "# Size of feature maps in generator\n",
        "ngf = 64\n",
        "\n",
        "# Size of feature maps in discriminator\n",
        "ndf = 64\n",
        "\n",
        "# Number of training epochs\n",
        "num_epochs = 5\n",
        "\n",
        "# Learning rate for optimizers\n",
        "lr = 0.0002\n",
        "\n",
        "# Beta1 hyperparameter for Adam optimizers\n",
        "beta1 = 0.5\n",
        "\n",
        "# Number of GPUs available. Use 0 for CPU mode.\n",
        "ngpu = 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z0f-OYxoane"
      },
      "source": [
        "# Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "RTt_yg3Eza6V",
        "outputId": "6322b879-cea0-4429-d5a1-e21606e6c4ba"
      },
      "outputs": [],
      "source": [
        "def image_load(file_path: str) ->np.ndarray:\n",
        "    img = cv2.imread(file_path)[:,:,: :-1] # Read image in BRG and convert to RGB\n",
        "\n",
        "    return img\n",
        "\n",
        "def show_img(img:np.ndarray,title:str ) -> None:\n",
        "    fig= px.imshow(img,title=title)\n",
        "    fig.show()\n",
        "\n",
        "show_img(image_load(dataroot+\"/kota_64_1781.jpeg\"),\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Custom Dataset Class\n",
        "Definition of ImageFolderCustom class based on torch Dataset class in order to load custom dataset. Class created on the [article](https://www.learnpytorch.io/04_pytorch_custom_datasets/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "diHZ9sKNn_xJ",
        "outputId": "a4826a41-6db5-4d33-d383-3a1b3b7f53fa"
      },
      "outputs": [],
      "source": [
        "# We can use an image folder dataset the way we have it setup.\n",
        "# Define Dataset class\n",
        "\n",
        "# 1. Subclass torch.utils.data.Dataset\n",
        "class ImageFolderCustom(torch.utils.data.Dataset):\n",
        "\n",
        "    # 2. Initialize with a targ_dir parameter\n",
        "    def __init__(self, targ_dir: str, transform=None) -> None:\n",
        "\n",
        "        # 3. Create class attributes\n",
        "        # Get all image paths\n",
        "        self.paths = list(pathlib.Path(targ_dir).glob(\"*.jpeg\"))\n",
        "        print(self.paths)\n",
        "        # Setup transforms\n",
        "        self.transform = transform\n",
        "\n",
        "        # Create classes and class_to_idx attributes\n",
        "        self.classes, self.class_to_idx = ['cat'], {'cat' : 1} #find_classes(targ_dir)\n",
        "\n",
        "    # 4. Make function to load images\n",
        "    def load_image(self, index: int) -> Image.Image:\n",
        "        \"Opens an image via a path and returns it.\"\n",
        "        image_path = self.paths[index]\n",
        "        return Image.open(image_path)\n",
        "\n",
        "    # 5. Overwrite the __len__() method (optional but recommended for subclasses of torch.utils.data.Dataset)\n",
        "    def __len__(self) -> int:\n",
        "        \"Returns the total number of samples.\"\n",
        "        return len(self.paths)\n",
        "\n",
        "    # 6. Overwrite the __getitem__() method (required for subclasses of torch.utils.data.Dataset)\n",
        "    def __getitem__(self, index: int) -> torch.Tensor:\n",
        "        \"Returns one sample of data (X,y).\"\n",
        "        img = self.load_image(index)\n",
        "        class_name  = 'cat'#self.paths[index].parent.name  expects path in data_folder/class_name/image.jpeg\n",
        "        class_idx = self.class_to_idx[class_name]\n",
        "\n",
        "        # Transform if necessary\n",
        "        if self.transform:\n",
        "            return self.transform(img),class_idx # return data\n",
        "        else:\n",
        "            return img, class_idx# return data\n",
        "\n",
        "#Get dataset\n",
        "def get_dataset(dataset_path) -> torch.utils.data.Dataset:\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
        "    ])\n",
        "    train_set = ImageFolderCustom(\n",
        "        targ_dir =  dataset_path,\n",
        "        transform = transform\n",
        "    )\n",
        "    return train_set\n",
        "\n",
        "\n",
        "# Loading data from Google Drive\n",
        "drive.mount('/content/drive/')\n",
        "dataset = get_dataset(dataroot)\n",
        "# Create the dataloader\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,\n",
        "                                         shuffle=True, num_workers=workers)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Visualization of a few loaded photos to check the results of load."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "-Kyx8i9zysMR",
        "outputId": "d067b121-30ff-454d-bc63-34cf70a1d4a6"
      },
      "outputs": [],
      "source": [
        "# Decide which device we want to run on\n",
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")\n",
        "\n",
        "# Plot some training images\n",
        "real_batch = next(iter(dataloader))\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Training Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=2, normalize=True).cpu(),(1,2,0)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img alt=\"Dataset\" src=\"img/bg_5ep/Dataset.png\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COuOWJswsvmE"
      },
      "source": [
        "# Model Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LHaU2TKtAIO"
      },
      "source": [
        "## Weights Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5oTqHnPsvLa"
      },
      "outputs": [],
      "source": [
        "# custom weights initialization called on ``netG`` and ``netD``\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yLSdQW5BtVjc"
      },
      "source": [
        "## Generator Class Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1OI6rTSptkwZ"
      },
      "outputs": [],
      "source": [
        "# Generator Code\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Generator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is Z, going into a convolution\n",
        "            nn.ConvTranspose2d( nz, ngf * 8, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 8),\n",
        "            nn.ReLU(True),\n",
        "            # state size. ``(ngf*8) x 4 x 4``\n",
        "            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 4),\n",
        "            nn.ReLU(True),\n",
        "            # state size. ``(ngf*4) x 8 x 8``\n",
        "            nn.ConvTranspose2d( ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf * 2),\n",
        "            nn.ReLU(True),\n",
        "            # state size. ``(ngf*2) x 16 x 16``\n",
        "            nn.ConvTranspose2d( ngf * 2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf),\n",
        "            nn.ReLU(True),\n",
        "            # state size. ``(ngf) x 32 x 32``\n",
        "            nn.ConvTranspose2d( ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "            # state size. ``(nc) x 64 x 64``\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llLzJa4xt7BH"
      },
      "source": [
        "## Generator Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EcxzSUTGuDeV",
        "outputId": "da4852bd-8e2e-4274-e822-4bce05791122"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generator(\n",
            "  (main): Sequential(\n",
            "    (0): ConvTranspose2d(100, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): ReLU(inplace=True)\n",
            "    (3): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): ReLU(inplace=True)\n",
            "    (6): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): ReLU(inplace=True)\n",
            "    (9): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): ReLU(inplace=True)\n",
            "    (12): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (13): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Create the generator\n",
        "netG = Generator(ngpu).to(device)\n",
        "\n",
        "# Handle multi-GPU if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netG = nn.DataParallel(netG, list(range(ngpu)))\n",
        "\n",
        "# Apply the ``weights_init`` function to randomly initialize all weights\n",
        "#  to ``mean=0``, ``stdev=0.02``.\n",
        "netG.apply(weights_init)\n",
        "\n",
        "# Print the model\n",
        "print(netG)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsKhOPyhtmTf"
      },
      "source": [
        "## Discriminator Class Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bS-2RGOotplP"
      },
      "outputs": [],
      "source": [
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, ngpu):\n",
        "        super(Discriminator, self).__init__()\n",
        "        self.ngpu = ngpu\n",
        "        self.main = nn.Sequential(\n",
        "            # input is ``(nc) x 64 x 64``\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. ``(ndf) x 32 x 32``\n",
        "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 2),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. ``(ndf*2) x 16 x 16``\n",
        "            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 4),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. ``(ndf*4) x 8 x 8``\n",
        "            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ndf * 8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            # state size. ``(ndf*8) x 4 x 4``\n",
        "            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, input):\n",
        "        return self.main(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iGJB5rSudfq"
      },
      "source": [
        "## Discriminator Initialization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39v1NZTluhsv",
        "outputId": "a81d6f3f-e0d8-4430-e73f-b713f2424ac7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Discriminator(\n",
            "  (main): Sequential(\n",
            "    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (10): LeakyReLU(negative_slope=0.2, inplace=True)\n",
            "    (11): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n",
            "    (12): Sigmoid()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Create the Discriminator\n",
        "netD = Discriminator(ngpu).to(device)\n",
        "\n",
        "# Handle multi-GPU if desired\n",
        "if (device.type == 'cuda') and (ngpu > 1):\n",
        "    netD = nn.DataParallel(netD, list(range(ngpu)))\n",
        "\n",
        "# Apply the ``weights_init`` function to randomly initialize all weights\n",
        "# like this: ``to mean=0, stdev=0.2``.\n",
        "netD.apply(weights_init)\n",
        "\n",
        "# Print the model\n",
        "print(netD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIp4iJvJunMG"
      },
      "source": [
        "## Optimizer Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PRLF2b5utej"
      },
      "outputs": [],
      "source": [
        "# Initialize the ``BCELoss`` function\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Create batch of latent vectors that we will use to visualize\n",
        "#  the progression of the generator\n",
        "fixed_noise = torch.randn(64, nz, 1, 1, device=device)\n",
        "\n",
        "# Establish convention for real and fake labels during training\n",
        "real_label = 1.\n",
        "fake_label = 0.\n",
        "\n",
        "# Setup Adam optimizers for both G and D\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uykZHC2muxEI"
      },
      "source": [
        "# Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h6tUNb0du040",
        "outputId": "0c69dabf-04f4-4811-c806-0d4fe15aa178"
      },
      "outputs": [],
      "source": [
        "# Training Loop\n",
        "\n",
        "# Lists to keep track of progress\n",
        "img_list = []\n",
        "G_losses = []\n",
        "D_losses = []\n",
        "iters = 0\n",
        "\n",
        "print(\"Starting Training Loop...\")\n",
        "\n",
        "start_time = time()\n",
        "iter_start_time = start_time\n",
        "# For each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    # For each batch in the dataloader\n",
        "    for i, data in enumerate(dataloader, 0):\n",
        "\n",
        "        ############################\n",
        "        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n",
        "        ###########################\n",
        "        ## Train with all-real batch\n",
        "        netD.zero_grad()\n",
        "        # Format batch\n",
        "        real_cpu = data[0].to(device)\n",
        "        b_size = real_cpu.size(0)\n",
        "        label = torch.full((b_size,), real_label, dtype=torch.float, device=device)\n",
        "        # Forward pass real batch through D\n",
        "        output = netD(real_cpu).view(-1)\n",
        "        # Calculate loss on all-real batch\n",
        "        errD_real = criterion(output, label)\n",
        "        # Calculate gradients for D in backward pass\n",
        "        errD_real.backward()\n",
        "        D_x = output.mean().item()\n",
        "\n",
        "        ## Train with all-fake batch\n",
        "        # Generate batch of latent vectors\n",
        "        noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "        # Generate fake image batch with G\n",
        "        fake = netG(noise)\n",
        "        label.fill_(fake_label)\n",
        "        # Classify all fake batch with D\n",
        "        output = netD(fake.detach()).view(-1)\n",
        "        # Calculate D's loss on the all-fake batch\n",
        "        errD_fake = criterion(output, label)\n",
        "        # Calculate the gradients for this batch, accumulated (summed) with previous gradients\n",
        "        errD_fake.backward()\n",
        "        D_G_z1 = output.mean().item()\n",
        "        # Compute error of D as sum over the fake and the real batches\n",
        "        errD = errD_real + errD_fake\n",
        "        # Update D\n",
        "        optimizerD.step()\n",
        "\n",
        "        ############################\n",
        "        # (2) Update G network: maximize log(D(G(z)))\n",
        "        ###########################\n",
        "        netG.zero_grad()\n",
        "        label.fill_(real_label)  # fake labels are real for generator cost\n",
        "        # Since we just updated D, perform another forward pass of all-fake batch through D\n",
        "        output = netD(fake).view(-1)\n",
        "        # Calculate G's loss based on this output\n",
        "        errG = criterion(output, label)\n",
        "        # Calculate gradients for G\n",
        "        errG.backward()\n",
        "        D_G_z2 = output.mean().item()\n",
        "        # Update G\n",
        "        optimizerG.step()\n",
        "\n",
        "        # Output training stats\n",
        "        if i % 50 == 0:\n",
        "            print('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n",
        "                  % (epoch, num_epochs, i, len(dataloader),\n",
        "                     errD.item(), errG.item(), D_x, D_G_z1, D_G_z2))\n",
        "            print (f\"time per 50 iterations: {time()-iter_start_time}\")\n",
        "            iter_start_time = time()\n",
        "\n",
        "        # Save Losses for plotting later\n",
        "        G_losses.append(errG.item())\n",
        "        D_losses.append(errD.item())\n",
        "\n",
        "        # Check how the generator is doing by saving G's output on fixed_noise\n",
        "        if (iters % 500 == 0) or ((epoch == num_epochs-1) and (i == len(dataloader)-1)):\n",
        "            with torch.no_grad():\n",
        "                fake = netG(fixed_noise).detach().cpu()\n",
        "            img_list.append(vutils.make_grid(fake, padding=2, normalize=True))\n",
        "\n",
        "        iters += 1\n",
        "    print(f\"Time per epoc{(time()-start_time)/60}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CU3s9Khtha92"
      },
      "source": [
        "## Saving Model\n",
        "Saving model with pickle library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ERLrbj12hapx"
      },
      "outputs": [],
      "source": [
        "filenameG = 'cat_generator.sav'\n",
        "pickle.dump(netG, open(filenameG, 'wb'))\n",
        "\n",
        "filenameD = 'cat_discriminator.sav'\n",
        "pickle.dump(netD, open(filenameD, 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOP_tewwllwm"
      },
      "outputs": [],
      "source": [
        "!cp cat_generator.sav /content/drive/MyDrive/1_Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVX4cIFxl-MV"
      },
      "outputs": [],
      "source": [
        "!cp cat_discriminator.sav /content/drive/MyDrive/1_Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading Generator to test if the model was saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "wwwaQzbam__f",
        "outputId": "b22f8e1a-4509-4e38-9fd4-6fbcaf09e67b"
      },
      "outputs": [],
      "source": [
        "noise = torch.randn(b_size, nz, 1, 1, device=device)\n",
        "\n",
        "\n",
        "loaded_model = pickle.load(open(\"/content/drive/MyDrive/1_Models/\"+filenameG, 'rb'))\n",
        "result = loaded_model(noise).cpu().detach()\n",
        "fake  = vutils.make_grid(result, padding=2, normalize=True)\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.imshow(np.transpose(fake,(1,2,0)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img alt=\"Saved model\" src=\"img/bg_5ep/Saved_model.png\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i29jPIkIvA3K"
      },
      "source": [
        "# Results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2rL9MXvvPJo"
      },
      "source": [
        "## Loss vs training plot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "WJpbYbthvCKi",
        "outputId": "52065925-5ea1-4a60-9c80-97169994c661"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.title(\"Generator and Discriminator Loss During Training\")\n",
        "plt.plot(G_losses,label=\"G\")\n",
        "plt.plot(D_losses,label=\"D\")\n",
        "plt.xlabel(\"iterations\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img alt=\"Loss function\" src=\"img/bg_5ep/Loss_function.png\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "20TL7EKavXQx"
      },
      "source": [
        "## Visualization of Generator’s progression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "r_lc6ZJjvf0L",
        "outputId": "ad5314db-6c73-4281-ad6d-fc2df3573f17"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize=(8,8))\n",
        "plt.axis(\"off\")\n",
        "ims = [[plt.imshow(np.transpose(i,(1,2,0)), animated=True)] for i in img_list]\n",
        "ani = animation.ArtistAnimation(fig, ims, interval=1000, repeat_delay=1000, blit=True)\n",
        "\n",
        "HTML(ani.to_jshtml())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img alt=\"Model progress\" src=\"img/bg_5ep/Train_vis.gif\" />"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OzBEptQvmht"
      },
      "source": [
        "## Real vs. Fake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "id": "jiCHjBNfvv92",
        "outputId": "2875089d-b62d-4e53-8de6-c46afb5926a5"
      },
      "outputs": [],
      "source": [
        "# Grab a batch of real images from the dataloader\n",
        "real_batch = next(iter(dataloader))\n",
        "\n",
        "# Plot the real images\n",
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(1,2,1)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Real Images\")\n",
        "plt.imshow(np.transpose(vutils.make_grid(real_batch[0].to(device)[:64], padding=5, normalize=True).cpu(),(1,2,0)))\n",
        "\n",
        "# Plot the fake images from the last epoch\n",
        "plt.subplot(1,2,2)\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Fake Images\")\n",
        "plt.imshow(np.transpose(img_list[-1],(1,2,0)))\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img alt=\"Real vs fake\" src=\"img/bg_5ep/Real_vs_fake.png\" />"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
